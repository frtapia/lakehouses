# Databricks notebook source
# MAGIC %md
# MAGIC # üìå Databricks Auto Loader
# MAGIC
# MAGIC ## üîπ ¬øQu√© es Auto Loader?
# MAGIC Auto Loader es una herramienta en Databricks que permite la ingesta continua de datos desde almacenamiento en la nube (Azure Blob Storage, AWS S3, Google Cloud Storage, etc.). Utiliza **esquema evolutivo**, procesamiento incremental y es altamente escalable.
# MAGIC
# MAGIC [Opciones] (https://docs.databricks.com/aws/en/ingestion/cloud-object-storage/auto-loader/options)
# MAGIC
# MAGIC
# MAGIC ## ‚öôÔ∏è **Opciones principales de Auto Loader**
# MAGIC
# MAGIC ### 1Ô∏è‚É£ **Opciones de origen (`source`)**
# MAGIC Auto Loader admite m√∫ltiples formatos de archivos:
# MAGIC - **`cloudFiles.format`** ‚Üí Define el formato de los archivos.
# MAGIC   - Valores: `csv`, `json`, `parquet`, `avro`, `orc`, `text`.
# MAGIC   
# MAGIC Ejemplo:
# MAGIC ```python
# MAGIC spark.readStream.format("cloudFiles") \
# MAGIC   .option("cloudFiles.format", "json") \
# MAGIC   .load("s3://bucket/data/")
# MAGIC ```
# MAGIC
# MAGIC
# MAGIC
# MAGIC ### 2Ô∏è‚É£ **Opciones de detecci√≥n de archivos (`file detection`)**
# MAGIC
# MAGIC - **`cloudFiles.schemaLocation`** ‚Üí Ubicaci√≥n donde se guarda el esquema detectado.
# MAGIC - **`cloudFiles.maxFilesPerTrigger`** ‚Üí N√∫mero m√°ximo de archivos procesados en cada batch.
# MAGIC - **`cloudFiles.includeExistingFiles`** ‚Üí Si `true`, procesa archivos existentes al inicio.
# MAGIC - **`cloudFiles.allowOverwrites`** ‚Üí Si `true`, permite la sobreescritura de archivos.
# MAGIC
# MAGIC Ejemplo:
# MAGIC ```python
# MAGIC .option("cloudFiles.schemaLocation", "dbfs:/schemas/ingestion/") \
# MAGIC .option("cloudFiles.includeExistingFiles", "true")
# MAGIC ```
# MAGIC
# MAGIC
# MAGIC
# MAGIC ### 3Ô∏è‚É£ **Opciones de inferencia de esquema (`schema inference`)**
# MAGIC
# MAGIC - **`cloudFiles.inferColumnTypes`** ‚Üí Convierte autom√°ticamente valores num√©ricos y booleanos detectados como string.
# MAGIC - **`cloudFiles.schemaEvolutionMode`** ‚Üí Permite manejar cambios en el esquema.
# MAGIC   - `failOnNewColumns`: Falla si se detectan nuevas columnas.
# MAGIC   - `addNewColumns`: Agrega nuevas columnas autom√°ticamente.
# MAGIC   
# MAGIC Ejemplo:
# MAGIC ```python
# MAGIC .option("cloudFiles.schemaEvolutionMode", "addNewColumns")
# MAGIC ```
# MAGIC
# MAGIC
# MAGIC
# MAGIC ### 4Ô∏è‚É£ **Opciones de filtrado y exclusi√≥n de archivos (`file filtering`)**
# MAGIC
# MAGIC - **`cloudFiles.pathGlobFilter`** ‚Üí Filtra archivos por nombre usando expresiones regulares.
# MAGIC - **`cloudFiles.excludePattern`** ‚Üí Excluye archivos que coincidan con un patr√≥n espec√≠fico.
# MAGIC
# MAGIC Ejemplo:
# MAGIC ```python
# MAGIC .option("cloudFiles.pathGlobFilter", "*.json") \
# MAGIC .option("cloudFiles.excludePattern", "*_backup.json")
# MAGIC ```
# MAGIC
# MAGIC
# MAGIC ### 5Ô∏è‚É£ **Opciones de rendimiento (`performance tuning`)**
# MAGIC
# MAGIC - **`cloudFiles.useNotifications`** ‚Üí Usa eventos de almacenamiento para detectar cambios en lugar de escanear.
# MAGIC - **`cloudFiles.queueName`** ‚Üí Nombre de la cola de mensajes para recibir eventos de cambios en el almacenamiento.
# MAGIC - **`cloudFiles.backfillInterval`** ‚Üí Intervalo de rean√°lisis de archivos nuevos.
# MAGIC
# MAGIC Ejemplo:
# MAGIC ```python
# MAGIC .option("cloudFiles.useNotifications", "true") \
# MAGIC .option("cloudFiles.queueName", "storage-event-queue")
# MAGIC ```
# MAGIC
# MAGIC
# MAGIC ### 6Ô∏è‚É£ **Opciones de manejo de errores (`error handling`)**
# MAGIC
# MAGIC - **`cloudFiles.schemaHints`** ‚Üí Define manualmente el esquema esperado.
# MAGIC - **`cloudFiles.ignoreCorruptFiles`** ‚Üí Ignora archivos corruptos.
# MAGIC - **`cloudFiles.ignoreMissingFiles`** ‚Üí Ignora archivos eliminados mientras el proceso de ingesta est√° en curso.
# MAGIC
# MAGIC Ejemplo:
# MAGIC ```python
# MAGIC .option("cloudFiles.schemaHints", "id LONG, name STRING, timestamp TIMESTAMP") \
# MAGIC .option("cloudFiles.ignoreCorruptFiles", "true")
# MAGIC ```
# MAGIC
# MAGIC
# MAGIC ## ‚úÖ **Ejemplo completo de Auto Loader**
# MAGIC
# MAGIC ```python
# MAGIC df = spark.readStream.format("cloudFiles") \
# MAGIC   .option("cloudFiles.format", "json") \
# MAGIC   .option("cloudFiles.schemaLocation", "dbfs:/schemas/ingestion/") \
# MAGIC   .option("cloudFiles.inferColumnTypes", "true") \
# MAGIC   .option("cloudFiles.includeExistingFiles", "true") \
# MAGIC   .option("cloudFiles.schemaEvolutionMode", "addNewColumns") \
# MAGIC   .load("s3://my-bucket/data/")
# MAGIC
# MAGIC df.writeStream.format("delta") \
# MAGIC   .option("checkpointLocation", "dbfs:/checkpoints/data/") \
# MAGIC   .start("dbfs:/delta/data/")
# MAGIC ```
# MAGIC